{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fa2f4f",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8969028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install sentence-transformers langchain langchain-community python-docx pdfplumber numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f551c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import application modules\n",
    "from app.parsers import ResumeParser, JobParser\n",
    "from app.embeddings import EmbeddingService, SimilarityMatcher\n",
    "from app.embeddings.similarity import compute_skill_overlap\n",
    "from app.chains import ExplanationChain\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aad3655",
   "metadata": {},
   "source": [
    "## 2. Sample Data\n",
    "\n",
    "Let's create some sample resumes and job descriptions for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d49398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Resume 1: Data Scientist\n",
    "resume_1_text = \"\"\"\n",
    "John Smith\n",
    "john.smith@email.com | (555) 123-4567\n",
    "\n",
    "PROFESSIONAL SUMMARY\n",
    "Experienced Data Scientist with 5+ years of expertise in machine learning, \n",
    "statistical analysis, and data visualization. Passionate about leveraging \n",
    "AI to solve complex business problems.\n",
    "\n",
    "SKILLS\n",
    "Python, R, SQL, TensorFlow, PyTorch, Scikit-learn, Pandas, NumPy, \n",
    "Machine Learning, Deep Learning, NLP, Computer Vision, Statistics,\n",
    "Data Visualization, Tableau, Power BI, AWS, Docker, Git\n",
    "\n",
    "EXPERIENCE\n",
    "Senior Data Scientist at TechCorp Inc.\n",
    "2020 - Present\n",
    "- Built ML models for customer churn prediction achieving 92% accuracy\n",
    "- Developed NLP pipeline for sentiment analysis of customer feedback\n",
    "- Led a team of 3 junior data scientists\n",
    "\n",
    "Data Scientist at DataAnalytics Co.\n",
    "2018 - 2020\n",
    "- Created predictive models for sales forecasting\n",
    "- Implemented recommendation systems using collaborative filtering\n",
    "- Built ETL pipelines processing 10TB+ daily\n",
    "\n",
    "EDUCATION\n",
    "Master of Science in Computer Science\n",
    "Stanford University, 2018\n",
    "\n",
    "Bachelor of Science in Mathematics\n",
    "UC Berkeley, 2016\n",
    "\n",
    "CERTIFICATIONS\n",
    "- AWS Certified Machine Learning Specialty\n",
    "- Google Cloud Professional Data Engineer\n",
    "\"\"\"\n",
    "\n",
    "# Sample Resume 2: Software Engineer\n",
    "resume_2_text = \"\"\"\n",
    "Sarah Johnson\n",
    "sarah.j@email.com | (555) 987-6543\n",
    "\n",
    "SUMMARY\n",
    "Full-stack software engineer with 4 years of experience building \n",
    "scalable web applications. Expert in React, Node.js, and cloud services.\n",
    "\n",
    "SKILLS\n",
    "JavaScript, TypeScript, React, Angular, Node.js, Express, Python,\n",
    "Django, PostgreSQL, MongoDB, Redis, AWS, Docker, Kubernetes,\n",
    "CI/CD, Git, Agile, REST API, GraphQL\n",
    "\n",
    "EXPERIENCE\n",
    "Software Engineer at WebTech Solutions\n",
    "2021 - Present\n",
    "- Developed React-based dashboard serving 100K+ users\n",
    "- Built microservices architecture using Node.js and Docker\n",
    "- Reduced API response time by 40% through optimization\n",
    "\n",
    "Junior Developer at StartupXYZ\n",
    "2020 - 2021\n",
    "- Built e-commerce platform using Django and React\n",
    "- Implemented payment integration with Stripe API\n",
    "\n",
    "EDUCATION\n",
    "Bachelor of Science in Computer Science\n",
    "MIT, 2020\n",
    "\"\"\"\n",
    "\n",
    "# Sample Resume 3: Marketing Analyst\n",
    "resume_3_text = \"\"\"\n",
    "Michael Chen\n",
    "m.chen@email.com | (555) 456-7890\n",
    "\n",
    "PROFILE\n",
    "Marketing analyst with strong data analysis skills and 3 years \n",
    "of experience in digital marketing and campaign optimization.\n",
    "\n",
    "SKILLS\n",
    "Excel, SQL, Google Analytics, Tableau, Python, R, Statistics,\n",
    "A/B Testing, SEO, SEM, Social Media Marketing, Content Strategy,\n",
    "Market Research, Campaign Analysis, Data Visualization\n",
    "\n",
    "EXPERIENCE\n",
    "Marketing Analyst at BrandCo\n",
    "2022 - Present\n",
    "- Analyzed marketing campaign performance across channels\n",
    "- Built dashboards tracking KPIs for executive team\n",
    "- Increased ROI by 25% through data-driven optimization\n",
    "\n",
    "Marketing Coordinator at MediaAgency\n",
    "2021 - 2022\n",
    "- Managed social media accounts with 500K followers\n",
    "- Conducted market research and competitor analysis\n",
    "\n",
    "EDUCATION\n",
    "Bachelor of Business Administration - Marketing\n",
    "NYU Stern School of Business, 2021\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ Sample resumes created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e651fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Job Descriptions\n",
    "\n",
    "job_1_text = \"\"\"\n",
    "Job Title: Senior Machine Learning Engineer\n",
    "Company: AI Innovations Inc.\n",
    "Location: San Francisco, CA (Hybrid)\n",
    "\n",
    "About Us:\n",
    "AI Innovations is a leading AI company developing cutting-edge ML solutions.\n",
    "\n",
    "Responsibilities:\n",
    "- Design and implement ML models for production systems\n",
    "- Lead ML projects from research to deployment\n",
    "- Mentor junior team members\n",
    "- Collaborate with product teams on AI features\n",
    "\n",
    "Requirements:\n",
    "- 5+ years experience in machine learning\n",
    "- Strong proficiency in Python, TensorFlow or PyTorch\n",
    "- Experience with NLP or Computer Vision\n",
    "- Knowledge of MLOps and model deployment\n",
    "- Master's or PhD in CS, Statistics, or related field\n",
    "\n",
    "Preferred:\n",
    "- Experience with LLMs and Generative AI\n",
    "- Publications in top ML conferences\n",
    "- AWS or GCP certification\n",
    "\n",
    "Benefits:\n",
    "- Competitive salary ($180K - $250K)\n",
    "- Stock options\n",
    "- Health insurance\n",
    "- Remote flexibility\n",
    "\"\"\"\n",
    "\n",
    "job_2_text = \"\"\"\n",
    "Job Title: Full Stack Developer\n",
    "Company: TechStartup Co.\n",
    "Location: Remote\n",
    "\n",
    "We're looking for a passionate full-stack developer to join our team!\n",
    "\n",
    "What You'll Do:\n",
    "- Build and maintain web applications using React and Node.js\n",
    "- Design RESTful APIs and database schemas\n",
    "- Write clean, maintainable code with tests\n",
    "- Participate in code reviews and agile ceremonies\n",
    "\n",
    "Requirements:\n",
    "- 3+ years of full-stack development experience\n",
    "- Proficiency in JavaScript/TypeScript, React, Node.js\n",
    "- Experience with SQL and NoSQL databases\n",
    "- Familiarity with cloud services (AWS/GCP/Azure)\n",
    "- Strong communication skills\n",
    "\n",
    "Nice to Have:\n",
    "- Experience with Docker and Kubernetes\n",
    "- Knowledge of GraphQL\n",
    "- Contributions to open source projects\n",
    "\n",
    "Salary: $120K - $160K\n",
    "\"\"\"\n",
    "\n",
    "job_3_text = \"\"\"\n",
    "Job Title: Data Analyst\n",
    "Company: RetailGiant Corp.\n",
    "Location: New York, NY\n",
    "\n",
    "About the Role:\n",
    "Join our analytics team to drive data-informed decisions across the organization.\n",
    "\n",
    "Key Responsibilities:\n",
    "- Analyze large datasets to identify trends and insights\n",
    "- Create dashboards and reports for stakeholders\n",
    "- Support marketing and sales teams with data analysis\n",
    "- Develop and maintain data pipelines\n",
    "\n",
    "Qualifications:\n",
    "- Bachelor's degree in Business, Statistics, or related field\n",
    "- 2+ years of data analysis experience\n",
    "- Expert in Excel and SQL\n",
    "- Experience with visualization tools (Tableau, Power BI)\n",
    "- Strong analytical and problem-solving skills\n",
    "\n",
    "Preferred Skills:\n",
    "- Python or R programming\n",
    "- Experience in retail or e-commerce industry\n",
    "- Knowledge of statistical analysis\n",
    "\n",
    "Compensation: $80K - $110K + bonus\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ Sample job descriptions created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee8063",
   "metadata": {},
   "source": [
    "## 3. Parse Resumes and Job Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d6f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parsers\n",
    "resume_parser = ResumeParser()\n",
    "job_parser = JobParser()\n",
    "\n",
    "print(\"‚úÖ Parsers initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8172d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse resumes from text\n",
    "resume_texts = [resume_1_text, resume_2_text, resume_3_text]\n",
    "resumes = []\n",
    "\n",
    "for i, text in enumerate(resume_texts):\n",
    "    # Create a temporary text file content\n",
    "    resume = resume_parser.parse(\n",
    "        file_content=text.encode('utf-8'),\n",
    "        file_name=f\"resume_{i+1}.txt\"\n",
    "    )\n",
    "    resumes.append(resume)\n",
    "    print(f\"\\nüìÑ Resume {i+1}: {resume.name}\")\n",
    "    print(f\"   Email: {resume.email}\")\n",
    "    print(f\"   Skills: {', '.join(resume.skills[:10])}...\")\n",
    "    print(f\"   Experience entries: {len(resume.experience)}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Parsed {len(resumes)} resumes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29647e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse job descriptions\n",
    "job_texts = [job_1_text, job_2_text, job_3_text]\n",
    "jobs = []\n",
    "\n",
    "for i, text in enumerate(job_texts):\n",
    "    job = job_parser.parse(text=text)\n",
    "    jobs.append(job)\n",
    "    print(f\"\\nüíº Job {i+1}: {job.title}\")\n",
    "    print(f\"   Company: {job.company}\")\n",
    "    print(f\"   Required Skills: {', '.join(job.required_skills[:8])}...\")\n",
    "    print(f\"   Experience: {job.required_experience}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Parsed {len(jobs)} job descriptions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c4fab",
   "metadata": {},
   "source": [
    "## 4. Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d48ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embedding service with SentenceTransformers (local, no API key needed)\n",
    "embedding_service = EmbeddingService(provider=\"sentence-transformers\")\n",
    "\n",
    "print(f\"Provider: {embedding_service.provider}\")\n",
    "print(f\"Embedding dimension: {embedding_service.embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for resumes\n",
    "print(\"Generating resume embeddings...\")\n",
    "resume_embeddings = embedding_service.embed_documents(resumes)\n",
    "print(f\"Resume embeddings shape: {resume_embeddings.shape}\")\n",
    "\n",
    "# Generate embeddings for jobs\n",
    "print(\"\\nGenerating job embeddings...\")\n",
    "job_embeddings = embedding_service.embed_documents(jobs)\n",
    "print(f\"Job embeddings shape: {job_embeddings.shape}\")\n",
    "\n",
    "print(\"\\n‚úÖ Embeddings generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd5f6e",
   "metadata": {},
   "source": [
    "## 5. Compute Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize similarity matcher\n",
    "matcher = SimilarityMatcher(similarity_metric=\"cosine\")\n",
    "\n",
    "# Compute similarity matrix\n",
    "similarity_matrix = matcher.compute_similarity_matrix(resume_embeddings, job_embeddings)\n",
    "\n",
    "# Create a nice DataFrame to display\n",
    "resume_names = [r.name or f\"Resume {i+1}\" for i, r in enumerate(resumes)]\n",
    "job_titles = [j.title or f\"Job {i+1}\" for i, j in enumerate(jobs)]\n",
    "\n",
    "similarity_df = pd.DataFrame(\n",
    "    similarity_matrix,\n",
    "    index=resume_names,\n",
    "    columns=job_titles\n",
    ")\n",
    "\n",
    "print(\"üìä Similarity Matrix (Resume vs Job):\")\n",
    "print(\"=\"*60)\n",
    "display(similarity_df.style.background_gradient(cmap='Blues').format(\"{:.2%}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9878a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match resumes to jobs\n",
    "matches = matcher.match_resumes_to_jobs(\n",
    "    resume_embeddings,\n",
    "    job_embeddings,\n",
    "    resumes,\n",
    "    jobs,\n",
    "    top_k=3,\n",
    "    threshold=0.0\n",
    ")\n",
    "\n",
    "print(\"üéØ Top Matches for Each Resume:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, resume_matches in enumerate(matches):\n",
    "    resume = resumes[i]\n",
    "    print(f\"\\nüìÑ {resume.name or resume.file_name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for match in resume_matches:\n",
    "        job = jobs[match.job_index]\n",
    "        score = match.similarity_score\n",
    "        \n",
    "        # Determine match quality\n",
    "        if score >= 0.7:\n",
    "            quality = \"üü¢ Excellent\"\n",
    "        elif score >= 0.5:\n",
    "            quality = \"üü° Good\"\n",
    "        else:\n",
    "            quality = \"üî¥ Low\"\n",
    "        \n",
    "        print(f\"  {quality} {job.title} ({score:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1b5ff3",
   "metadata": {},
   "source": [
    "## 6. Skill Overlap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b84e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze skill overlap between best matches\n",
    "print(\"üîç Skill Gap Analysis:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, resume in enumerate(resumes):\n",
    "    best_match = matches[i][0]  # Top match for this resume\n",
    "    job = jobs[best_match.job_index]\n",
    "    \n",
    "    overlap = compute_skill_overlap(resume.skills, job.required_skills)\n",
    "    \n",
    "    print(f\"\\nüìÑ {resume.name} ‚Üí üíº {job.title}\")\n",
    "    print(f\"   Match Score: {best_match.similarity_score:.1%}\")\n",
    "    print(f\"   Skill Coverage: {overlap['coverage_percentage']:.0f}% ({overlap['matched_count']}/{overlap['total_required']})\")\n",
    "    \n",
    "    if overlap['matching_skills']:\n",
    "        print(f\"   ‚úÖ Matching: {', '.join(list(overlap['matching_skills'])[:5])}\")\n",
    "    \n",
    "    if overlap['missing_skills']:\n",
    "        print(f\"   ‚ùå Missing: {', '.join(list(overlap['missing_skills'])[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce7389",
   "metadata": {},
   "source": [
    "## 7. AI-Powered Match Explanations (Optional)\n",
    "\n",
    "This section uses LangChain to generate detailed explanations. It requires either:\n",
    "- Ollama running locally with llama3.2 model\n",
    "- Google API key for Gemini\n",
    "\n",
    "If neither is available, you'll see a fallback message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e0c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to initialize explanation chain\n",
    "explanation_chain = None\n",
    "\n",
    "try:\n",
    "    # Try Ollama first (local)\n",
    "    explanation_chain = ExplanationChain(provider=\"ollama\")\n",
    "    print(\"‚úÖ Using Ollama for explanations\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Ollama not available: {e}\")\n",
    "    \n",
    "    # Try Google as fallback\n",
    "    import os\n",
    "    if os.getenv(\"GOOGLE_API_KEY\"):\n",
    "        try:\n",
    "            explanation_chain = ExplanationChain(provider=\"google\")\n",
    "            print(\"‚úÖ Using Google Gemini for explanations\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Google AI not available: {e}\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è Set GOOGLE_API_KEY environment variable to enable AI explanations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aed988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate explanation for best match\n",
    "if explanation_chain:\n",
    "    print(\"ü§ñ Generating AI-Powered Match Explanation...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get best overall match\n",
    "    best_resume_idx = 0  # John Smith (Data Scientist)\n",
    "    best_match = matches[best_resume_idx][0]\n",
    "    \n",
    "    resume = resumes[best_resume_idx]\n",
    "    job = jobs[best_match.job_index]\n",
    "    \n",
    "    print(f\"\\nAnalyzing: {resume.name} ‚Üí {job.title}\")\n",
    "    print(f\"Match Score: {best_match.similarity_score:.1%}\")\n",
    "    print()\n",
    "    \n",
    "    # Compute skill overlap for context\n",
    "    skill_overlap = compute_skill_overlap(resume.skills, job.required_skills)\n",
    "    \n",
    "    # Generate explanation\n",
    "    explanation = explanation_chain.explain_match(\n",
    "        resume, job, \n",
    "        best_match.similarity_score,\n",
    "        skill_overlap\n",
    "    )\n",
    "    \n",
    "    print(explanation.to_text())\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è AI explanations not available. Using quick summary instead.\")\n",
    "    print()\n",
    "    \n",
    "    # Generate simple summaries\n",
    "    for i, resume in enumerate(resumes):\n",
    "        best_match = matches[i][0]\n",
    "        job = jobs[best_match.job_index]\n",
    "        score = best_match.similarity_score\n",
    "        \n",
    "        resume_skills = set(s.lower() for s in resume.skills)\n",
    "        job_skills = set(s.lower() for s in job.required_skills)\n",
    "        matching = resume_skills & job_skills\n",
    "        \n",
    "        if score >= 0.7:\n",
    "            fit = \"excellent\"\n",
    "        elif score >= 0.5:\n",
    "            fit = \"good\"\n",
    "        else:\n",
    "            fit = \"moderate\"\n",
    "        \n",
    "        print(f\"üìÑ {resume.name} ‚Üí {job.title}\")\n",
    "        print(f\"   {fit.title()} match ({score:.0%}) with {len(matching)} matching skills\")\n",
    "        if matching:\n",
    "            print(f\"   Key matches: {', '.join(list(matching)[:4])}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a2f90",
   "metadata": {},
   "source": [
    "## 8. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create heatmap visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "im = ax.imshow(similarity_matrix, cmap='Blues', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "# Labels\n",
    "ax.set_xticks(range(len(job_titles)))\n",
    "ax.set_yticks(range(len(resume_names)))\n",
    "ax.set_xticklabels(job_titles, rotation=45, ha='right', fontsize=10)\n",
    "ax.set_yticklabels(resume_names, fontsize=10)\n",
    "\n",
    "# Add values on heatmap\n",
    "for i in range(len(resume_names)):\n",
    "    for j in range(len(job_titles)):\n",
    "        score = similarity_matrix[i, j]\n",
    "        color = 'white' if score > 0.5 else 'black'\n",
    "        ax.text(j, i, f'{score:.0%}', ha='center', va='center', color=color, fontsize=11)\n",
    "\n",
    "ax.set_xlabel('Job Positions', fontsize=12)\n",
    "ax.set_ylabel('Candidates', fontsize=12)\n",
    "ax.set_title('üéØ Resume-Job Similarity Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Similarity Score', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b41688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of best matches\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Prepare data\n",
    "candidates = []\n",
    "best_job = []\n",
    "scores = []\n",
    "\n",
    "for i, resume in enumerate(resumes):\n",
    "    best_match = matches[i][0]\n",
    "    job = jobs[best_match.job_index]\n",
    "    \n",
    "    candidates.append(resume.name or f\"Resume {i+1}\")\n",
    "    best_job.append(job.title or f\"Job {best_match.job_index+1}\")\n",
    "    scores.append(best_match.similarity_score)\n",
    "\n",
    "colors = ['#28a745' if s >= 0.7 else '#ffc107' if s >= 0.5 else '#dc3545' for s in scores]\n",
    "\n",
    "bars = ax.barh(candidates, scores, color=colors)\n",
    "\n",
    "# Add job labels on bars\n",
    "for bar, job_title, score in zip(bars, best_job, scores):\n",
    "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "            f'{job_title} ({score:.0%})', va='center', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Match Score', fontsize=12)\n",
    "ax.set_title('üèÜ Best Job Match for Each Candidate', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 1.3)\n",
    "ax.axvline(0.7, color='green', linestyle='--', alpha=0.5, label='Excellent (70%+)')\n",
    "ax.axvline(0.5, color='orange', linestyle='--', alpha=0.5, label='Good (50%+)')\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e34235",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This notebook demonstrated the complete workflow of the Smart Resume & Job Matcher:\n",
    "\n",
    "1. **Parsing**: Extracted structured information from resumes and job descriptions\n",
    "2. **Embedding**: Generated semantic vector representations using SentenceTransformers\n",
    "3. **Matching**: Computed cosine similarity to find best matches\n",
    "4. **Analysis**: Analyzed skill gaps and coverage\n",
    "5. **Explanation**: Generated AI-powered match explanations (when LLM available)\n",
    "6. **Visualization**: Created heatmaps and charts to visualize results\n",
    "\n",
    "### Key Findings:\n",
    "- **John Smith** (Data Scientist) is an excellent match for the ML Engineer role\n",
    "- **Sarah Johnson** (Software Engineer) matches well with the Full Stack Developer position\n",
    "- **Michael Chen** (Marketing Analyst) is best suited for the Data Analyst role\n",
    "\n",
    "### Next Steps:\n",
    "- Run the Streamlit app for an interactive UI: `streamlit run app/main.py`\n",
    "- Upload your own resumes and job descriptions\n",
    "- Configure different embedding providers (Ollama, Google) in `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121dab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ Demo Complete!\")\n",
    "print(\"\\nTo run the Streamlit app, execute:\")\n",
    "print(\"  streamlit run app/main.py\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
